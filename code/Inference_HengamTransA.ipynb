{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wYfViVSz2s-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inference HengamTransA"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install Libraries"
   ],
   "metadata": {
    "id": "-N7ucULGvmmr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install -q pytorch-lightning==1.5.10\n",
    "! pip install -q pytorch-crf==0.7.2\n",
    "! pip install -q transformers==4.16.2\n",
    "! pip install -q seqeval==1.2.2\n",
    "! pip install -q gdown --upgrade\n",
    "! pip install -q tqdm==4.62.3"
   ],
   "metadata": {
    "id": "BNHgwVzavlU_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare folder and files"
   ],
   "metadata": {
    "id": "H8Yqs7-OVbnn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download HengamTransA\n",
    "! wget https://huggingface.co/kargaranamir/Hengam/resolve/main/HengamTransA.pth"
   ],
   "metadata": {
    "id": "BNSZtFQ2RaS_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmK6V-wGzx7R",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqaswDc55pGu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TAGS_TABLE = ['B-TIM', 'I-TIM', 'B-DAT', 'I-DAT', 'O'] # Create Tag table\n",
    "MODEL_NAME = 'HengamTransA.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiFCEopXNmRp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l35D2afgGuxg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import primitive libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# import seqval to report classifier performance metrics\n",
    "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "# import torch related modules\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "\n",
    "# import pytorch lightning library\n",
    "import pytorch_lightning as pl\n",
    "from torchcrf import CRF as SUPERCRF\n",
    "\n",
    "# import NLTK to create better tokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Transformers : Roberta Model\n",
    "from transformers import XLMRobertaTokenizerFast\n",
    "from transformers import XLMRobertaModel, XLMRobertaConfig\n",
    "\n",
    "# import sklearn inorder to split data into train-evaluation-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import Typings\n",
    "from typing import Union,Dict,List,Tuple,Any,Optional\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJujx4BAUcdY",
    "outputId": "931adfc9-15ee-4b6a-d44d-577568208432",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# for sent tokenizer (nltk)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9ASUZ2n2aR2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## XLM-Roberta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs5yGEFN2gHP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TokenFromSubtoken\n",
    "- Code adapted from the following [file](https://github.com/deepmipt/DeepPavlov/blob/master/deeppavlov/models/torch_bert/torch_transformers_sequence_tagger.py)\n",
    "- DeepPavlov is an popular open source library for deep learning end-to-end dialog systems and chatbots.\n",
    "- Licensed under the Apache License, Version 2.0 (the \"License\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlP1uKJ9T8e4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TokenFromSubtoken(torch.nn.Module):\n",
    "\n",
    "    def forward(self, units: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Assemble token level units from subtoken level units\n",
    "        Args:\n",
    "            units: torch.Tensor of shape [batch_size, SUBTOKEN_seq_length, n_features]\n",
    "            mask: mask of token beginnings. For example: for tokens\n",
    "                    [[``[CLS]`` ``My``, ``capybara``, ``[SEP]``],\n",
    "                    [``[CLS]`` ``Your``, ``aar``, ``##dvark``, ``is``, ``awesome``, ``[SEP]``]]\n",
    "                the mask will be\n",
    "                    [[0, 1, 1, 0, 0, 0, 0],\n",
    "                    [0, 1, 1, 0, 1, 1, 0]]\n",
    "        Returns:\n",
    "            word_level_units: Units assembled from ones in the mask. For the\n",
    "                example above this units will correspond to the following\n",
    "                    [[``My``, ``capybara``],\n",
    "                    [``Your`, ``aar``, ``is``, ``awesome``,]]\n",
    "                the shape of this tensor will be [batch_size, TOKEN_seq_length, n_features]\n",
    "        \"\"\"\n",
    "        \n",
    "        device = units.device\n",
    "        nf_int = units.size()[-1]\n",
    "        batch_size = units.size()[0]\n",
    "\n",
    "        # number of TOKENS in each sentence\n",
    "        token_seq_lengths = torch.sum(mask, 1).to(torch.int64)\n",
    "        # number of words\n",
    "        n_words = torch.sum(token_seq_lengths)\n",
    "        # max token seq len\n",
    "        max_token_seq_len = torch.max(token_seq_lengths)\n",
    "\n",
    "        idxs = torch.stack(torch.nonzero(mask, as_tuple=True), dim=1)\n",
    "        # padding is for computing change from one sample to another in the batch\n",
    "        sample_ids_in_batch = torch.nn.functional.pad(input=idxs[:, 0], pad=[1, 0])\n",
    "        \n",
    "        a = (~torch.eq(sample_ids_in_batch[1:], sample_ids_in_batch[:-1])).to(torch.int64)\n",
    "        \n",
    "        # transforming sample start masks to the sample starts themselves\n",
    "        q = a * torch.arange(n_words, device=device).to(torch.int64)\n",
    "        count_to_substract = torch.nn.functional.pad(torch.masked_select(q, q.to(torch.bool)), [1, 0])\n",
    "\n",
    "        new_word_indices = torch.arange(n_words, device=device).to(torch.int64) - count_to_substract[torch.cumsum(a, 0)]\n",
    "        \n",
    "        n_total_word_elements = max_token_seq_len*torch.ones_like(token_seq_lengths, device=device).sum()\n",
    "        word_indices_flat = (idxs[:, 0] * max_token_seq_len + new_word_indices).to(torch.int64)\n",
    "        #x_mask = torch.sum(torch.nn.functional.one_hot(word_indices_flat, n_total_word_elements), 0)\n",
    "        #x_mask = x_mask.to(torch.bool)\n",
    "        x_mask = torch.zeros(n_total_word_elements, dtype=torch.bool, device=device)\n",
    "        x_mask[word_indices_flat] = torch.ones_like(word_indices_flat, device=device, dtype=torch.bool)\n",
    "        # to get absolute indices we add max_token_seq_len:\n",
    "        # idxs[:, 0] * max_token_seq_len -> [0, 0, 0, 1, 1, 2] * 2 = [0, 0, 0, 3, 3, 6]\n",
    "        # word_indices_flat -> [0, 0, 0, 3, 3, 6] + [0, 1, 2, 0, 1, 0] = [0, 1, 2, 3, 4, 6]\n",
    "        # total number of words in the batch (including paddings)\n",
    "        # batch_size * max_token_seq_len -> 3 * 3 = 9\n",
    "        # tf.one_hot(...) ->\n",
    "        # [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "        #  [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    "        #  [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "        #  [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "        #  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "        #  [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
    "        #  x_mask -> [1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
    "        nonword_indices_flat = (~x_mask).nonzero().squeeze(-1)\n",
    "\n",
    "        # get a sequence of units corresponding to the start subtokens of the words\n",
    "        # size: [n_words, n_features]\n",
    "        \n",
    "        elements = units[mask.bool()]\n",
    "\n",
    "        # prepare zeros for paddings\n",
    "        # size: [batch_size * TOKEN_seq_length - n_words, n_features]\n",
    "        paddings = torch.zeros_like(nonword_indices_flat, dtype=elements.dtype).unsqueeze(-1).repeat(1,nf_int).to(device)\n",
    "\n",
    "        # tensor_flat -> [x, x, x, x, x, 0, x, 0, 0]\n",
    "        tensor_flat_unordered = torch.cat([elements, paddings])\n",
    "        _, order_idx = torch.sort(torch.cat([word_indices_flat, nonword_indices_flat]))\n",
    "        tensor_flat = tensor_flat_unordered[order_idx]\n",
    "\n",
    "        tensor = torch.reshape(tensor_flat, (-1, max_token_seq_len, nf_int))\n",
    "        # tensor -> [[x, x, x],\n",
    "        #            [x, x, 0],\n",
    "        #            [x, 0, 0]]\n",
    "\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2We9RK24f29",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conditional Random Field \n",
    "- Code adopted form [torchcrf library](https://pytorch-crf.readthedocs.io/en/stable/)\n",
    "- we override veiterbi decoder in order to make it compatible with our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjXultXaUj-t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CRF(SUPERCRF):\n",
    "\n",
    "    # override veiterbi decoder in order to make it compatible with our code \n",
    "    def _viterbi_decode(self, emissions: torch.FloatTensor,\n",
    "                        mask: torch.ByteTensor) -> List[List[int]]:\n",
    "        # emissions: (seq_length, batch_size, num_tags)\n",
    "        # mask: (seq_length, batch_size)\n",
    "        assert emissions.dim() == 3 and mask.dim() == 2\n",
    "        assert emissions.shape[:2] == mask.shape\n",
    "        assert emissions.size(2) == self.num_tags\n",
    "        assert mask[0].all()\n",
    "\n",
    "        seq_length, batch_size = mask.shape\n",
    "\n",
    "        # Start transition and first emission\n",
    "        # shape: (batch_size, num_tags)\n",
    "        score = self.start_transitions + emissions[0]\n",
    "        history = []\n",
    "\n",
    "        # score is a tensor of size (batch_size, num_tags) where for every batch,\n",
    "        # value at column j stores the score of the best tag sequence so far that ends\n",
    "        # with tag j\n",
    "        # history saves where the best tags candidate transitioned from; this is used\n",
    "        # when we trace back the best tag sequence\n",
    "\n",
    "        # Viterbi algorithm recursive case: we compute the score of the best tag sequence\n",
    "        # for every possible next tag\n",
    "        for i in range(1, seq_length):\n",
    "            # Broadcast viterbi score for every possible next tag\n",
    "            # shape: (batch_size, num_tags, 1)\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "\n",
    "            # Broadcast emission score for every possible current tag\n",
    "            # shape: (batch_size, 1, num_tags)\n",
    "            broadcast_emission = emissions[i].unsqueeze(1)\n",
    "\n",
    "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
    "            # for each sample, entry at row i and column j stores the score of the best\n",
    "            # tag sequence so far that ends with transitioning from tag i to tag j and emitting\n",
    "            # shape: (batch_size, num_tags, num_tags)\n",
    "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
    "\n",
    "            # Find the maximum score over all possible current tag\n",
    "            # shape: (batch_size, num_tags)\n",
    "            next_score, indices = next_score.max(dim=1)\n",
    "\n",
    "            # Set score to the next score if this timestep is valid (mask == 1)\n",
    "            # and save the index that produces the next score\n",
    "            # shape: (batch_size, num_tags)\n",
    "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
    "            history.append(indices)\n",
    "\n",
    "        history = torch.stack(history, dim=0)\n",
    "\n",
    "        # End transition score\n",
    "        # shape: (batch_size, num_tags)\n",
    "        score += self.end_transitions\n",
    "\n",
    "        # Now, compute the best path for each sample\n",
    "\n",
    "        # shape: (batch_size,)\n",
    "        seq_ends = mask.long().sum(dim=0) - 1\n",
    "        best_tags_list = []\n",
    "\n",
    "        for idx in range(batch_size):\n",
    "            # Find the tag which maximizes the score at the last timestep; this is our best tag\n",
    "            # for the last timestep\n",
    "            _, best_last_tag = score[idx].max(dim=0)\n",
    "            best_tags = [best_last_tag]\n",
    "\n",
    "            # We trace back where the best last tag comes from, append that to our best tag\n",
    "            # sequence, and trace it back again, and so on\n",
    "            for i, hist in enumerate(torch.flip(history[:seq_ends[idx]], dims=(0,))):\n",
    "                best_last_tag = hist[idx][best_tags[-1]]\n",
    "                best_tags.append(best_last_tag)\n",
    "\n",
    "            best_tags = torch.stack(best_tags, dim=0)\n",
    "\n",
    "            # Reverse the order because we start from the last timestep\n",
    "            best_tags_list.append(torch.flip(best_tags, dims=(0,)))\n",
    "\n",
    "        best_tags_list = nn.utils.rnn.pad_sequence(best_tags_list, batch_first=True, padding_value=0)\n",
    "\n",
    "        return best_tags_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KdozEy46dT4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CRFLayer \n",
    "- Forward: decide output logits basaed on backbone network  \n",
    "- Decode: decode based on CRF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNBE1vxOUJCe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CRFLayer(nn.Module):\n",
    "    def __init__(self, embedding_size, n_labels):\n",
    "\n",
    "        super(CRFLayer, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.output_dense = nn.Linear(embedding_size,n_labels)\n",
    "        self.crf = CRF(n_labels, batch_first=True)\n",
    "        self.token_from_subtoken = TokenFromSubtoken()\n",
    "\n",
    "    # Forward: decide output logits basaed on backbone network  \n",
    "    def forward(self, embedding, mask):\n",
    "        logits = self.output_dense(self.dropout(embedding))\n",
    "        logits = self.token_from_subtoken(logits, mask)\n",
    "        pad_mask = self.token_from_subtoken(mask.unsqueeze(-1), mask).squeeze(-1).bool()\n",
    "        return logits, pad_mask\n",
    "\n",
    "    # Decode: decode based on CRF weights \n",
    "    def decode(self, logits, pad_mask):\n",
    "        return self.crf.decode(logits, pad_mask)\n",
    "\n",
    "    # Evaluation Loss: calculate mean log likelihood of CRF layer\n",
    "    def eval_loss(self, logits, targets, pad_mask):\n",
    "        mean_log_likelihood = self.crf(logits, targets, pad_mask, reduction='sum').mean()\n",
    "        return -mean_log_likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5ma5bWa7LaS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NERModel\n",
    "- Roberta Model with CRF Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VE7L4jPKTmPp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NERModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_labels:int, roberta_path:str):\n",
    "        super(NERModel,self).__init__()\n",
    "        self.roberta = XLMRobertaModel.from_pretrained(roberta_path)\n",
    "        self.crf = CRFLayer(self.roberta.config.hidden_size, n_labels)\n",
    "\n",
    "    # Forward: pass embedings to CRF layer in order to evaluate logits from suboword sequence\n",
    "    def forward(self, \n",
    "                input_ids:torch.Tensor,\n",
    "                attention_mask:torch.Tensor,\n",
    "                token_type_ids:torch.Tensor,\n",
    "                mask:torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        embedding = self.roberta(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 token_type_ids=token_type_ids)[0]\n",
    "        logits, pad_mask = self.crf(embedding, mask)\n",
    "        return logits, pad_mask\n",
    "\n",
    "    # Disable Gradient and Predict with model\n",
    "    @torch.no_grad()\n",
    "    def predict(self, inputs:Tuple[torch.Tensor]) -> torch.Tensor:\n",
    "        input_ids, attention_mask, token_type_ids, mask = inputs\n",
    "        logits, pad_mask = self(input_ids, attention_mask, token_type_ids, mask)\n",
    "        decoded = self.crf.decode(logits, pad_mask)\n",
    "        return decoded, pad_mask\n",
    "\n",
    "    # Decode: pass to crf decoder and decode based on CRF weights \n",
    "    def decode(self, logits, pad_mask):\n",
    "        \"\"\"Decode logits using CRF weights \n",
    "        \"\"\"\n",
    "        return self.crf.decode(logits, pad_mask) \n",
    "\n",
    "    # Evaluation Loss: pass to crf eval_loss and calculate mean log likelihood of CRF layer\n",
    "    def eval_loss(self, logits, targets, pad_mask):\n",
    "        return self.crf.eval_loss(logits, targets, pad_mask)\n",
    "\n",
    "    # Determine number of layers to be fine-tuned (!freeze) \n",
    "    def freeze_roberta(self, n_freeze:int=6):\n",
    "        for param in self.roberta.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.roberta.encoder.layer[n_freeze:].parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBly2y20Kd_Q",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NERTokenizer\n",
    "- NLTK tokenizer along with XLMRobertaTokenizerFast tokenizer\n",
    "- Code adapted from the following [file](https://github.com/ugurcanozalp/multilingual-ner/blob/main/multiner/utils/custom_tokenizer.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtYHE7bFSg0X",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NERTokenizer(object):\n",
    "\n",
    "    MAX_LEN=512\n",
    "    BATCH_LENGTH_LIMT = 380 # Max number of roberta tokens in one sentence.\n",
    "\n",
    "    # Modified version of http://stackoverflow.com/questions/36353125/nltk-regular-expression-tokenizer\n",
    "    PATTERN = r'''(?x)          # set flag to allow verbose regexps\n",
    "        (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A. or U.S.A # \n",
    "        | (?:\\d+\\.)           # numbers\n",
    "        | \\w+(?:[-.]\\w+)*     # words with optional internal hyphens\n",
    "        | \\$?\\d+(?:.\\d+)?%?   # currency and percentages, e.g. $12.40, 82%\n",
    "        | \\.\\.\\.              # ellipsis, and special chars below, includes ], [\n",
    "        | [-\\]\\[.؟،؛;\"'?,():_`“”/°º‘’″…#$%()*+<>=@\\\\^_{}|~❑&§\\!]\n",
    "        | \\u200c\n",
    "    '''\n",
    "\n",
    "    def __init__(self, base_model:str, to_device:str='cpu'):\n",
    "        super(NERTokenizer,self).__init__()\n",
    "        self.roberta_tokenizer = XLMRobertaTokenizerFast.from_pretrained(base_model, do_lower_case=False, padding=True, truncation=True)\n",
    "        self.to_device = to_device\n",
    "\n",
    "        self.word_tokenizer = RegexpTokenizer(self.PATTERN)\n",
    "        self.sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "    # tokenize batch of tokens\n",
    "    def tokenize_batch(self, inputs, pad_to = None) -> torch.Tensor:\n",
    "        batch = [inputs] if isinstance(inputs[0], str) else inputs\n",
    "        \n",
    "        input_ids, attention_mask, token_type_ids, mask = [], [], [], []\n",
    "        for tokens in batch:\n",
    "            input_ids_tmp, attention_mask_tmp, token_type_ids_tmp, mask_tmp = self._tokenize_words(tokens)\n",
    "            input_ids.append(input_ids_tmp)\n",
    "            attention_mask.append(attention_mask_tmp)\n",
    "            token_type_ids.append(token_type_ids_tmp)\n",
    "            mask.append(mask_tmp)\n",
    "\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.roberta_tokenizer.pad_token_id)\n",
    "        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "        token_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0)\n",
    "        mask = pad_sequence(mask, batch_first=True, padding_value=0)\n",
    "        # truncate MAX_LEN\n",
    "        if input_ids.shape[-1]>self.MAX_LEN:\n",
    "            input_ids = input_ids[:,:,:self.MAX_LEN]\n",
    "            attention_mask = attention_mask[:,:,:self.MAX_LEN]\n",
    "            token_type_ids = token_type_ids[:,:,:self.MAX_LEN]\n",
    "            mask = mask[:,:,:self.MAX_LEN]\n",
    "        \n",
    "        # extend pad \n",
    "        elif pad_to is not None and pad_to>input_ids.shape[1]:\n",
    "            bs = input_ids.shape[0]\n",
    "            padlen = pad_to-input_ids.shape[1]\n",
    "\n",
    "            input_ids_append = torch.tensor([self.roberta_tokenizer.pad_token_id], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
    "            input_ids = torch.cat([input_ids, input_ids_append], dim=-1)\n",
    "\n",
    "            attention_mask_append = torch.tensor([0], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
    "            attention_mask = torch.cat([attention_mask, attention_mask_append], dim=-1)\n",
    "\n",
    "            token_type_ids_append = torch.tensor([0], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
    "            token_type_ids = torch.cat([token_type_ids, token_type_ids_append], dim=-1)\n",
    "\n",
    "            mask_append = torch.tensor([0], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
    "            mask = torch.cat([mask, mask_append], dim=-1)\n",
    "\n",
    "        # truncate pad\n",
    "        elif pad_to is not None and pad_to<input_ids.shape[1]:\n",
    "            input_ids = input_ids[:,:,:pad_to]\n",
    "            attention_mask = attention_mask[:,:,:pad_to]\n",
    "            token_type_ids = token_type_ids[:,:,:pad_to]\n",
    "            mask = mask[:,:,:pad_to]\n",
    "\n",
    "        if isinstance(inputs[0], str):\n",
    "            return input_ids[0], attention_mask[0], token_type_ids[0], mask[0]\n",
    "        else:\n",
    "            return input_ids, attention_mask, token_type_ids, mask\n",
    "\n",
    "    # tokenize list of words with roberta tokenizer\n",
    "    def _tokenize_words(self, words):\n",
    "        roberta_tokens = []\n",
    "        mask = []\n",
    "        for word in words:\n",
    "            subtokens = self.roberta_tokenizer.tokenize(word)\n",
    "            roberta_tokens+=subtokens\n",
    "            n_subtoken = len(subtokens)\n",
    "            if n_subtoken>=1:\n",
    "                mask = mask + [1] + [0]*(n_subtoken-1)\n",
    "\n",
    "        # add special tokens [CLS] and [SeP]\n",
    "        roberta_tokens = [self.roberta_tokenizer.cls_token] + roberta_tokens + [self.roberta_tokenizer.sep_token]\n",
    "        mask = [0] + mask + [0]\n",
    "        input_ids = torch.tensor(self.roberta_tokenizer.convert_tokens_to_ids(roberta_tokens), dtype=torch.long).to(self.to_device)\n",
    "        attention_mask = torch.ones(len(mask), dtype=torch.long).to(self.to_device)\n",
    "        token_type_ids = torch.zeros(len(mask), dtype=torch.long).to(self.to_device)\n",
    "        mask = torch.tensor(mask, dtype=torch.long).to(self.to_device)\n",
    "        return input_ids, attention_mask, token_type_ids, mask\n",
    "\n",
    "    # sent_to_token: yield each sentence token with positional span using nltk\n",
    "    def sent_to_token(self, raw_text):\n",
    "        for offset, ending in self.sent_tokenizer.span_tokenize(raw_text):\n",
    "            sub_text = raw_text[offset:ending]\n",
    "            words, spans = [], []\n",
    "            flush = False\n",
    "            total_subtoken = 0\n",
    "            for start, end in self.word_tokenizer.span_tokenize(sub_text):\n",
    "                flush = True\n",
    "                start += offset\n",
    "                end += offset\n",
    "                words.append(raw_text[start:end])\n",
    "                spans.append((start,end))\n",
    "                total_subtoken += len(self.roberta_tokenizer.tokenize(words[-1]))\n",
    "                if (total_subtoken > self.BATCH_LENGTH_LIMT): \n",
    "                    # Print\n",
    "                    yield words[:-1],spans[:-1]\n",
    "                    spans = spans[len(spans)-1:]\n",
    "                    words = words[len(words)-1:]\n",
    "                    total_subtoken = sum([len(self.roberta_tokenizer.tokenize(word)) for word in words])\n",
    "                    flush = False\n",
    "\n",
    "            if flush and len(spans) > 0:\n",
    "                yield words,spans\n",
    "\n",
    "    # Extract (batch words span() from a raw sentence\n",
    "    def prepare_row_text(self, raw_text, batch_size=16):\n",
    "        words_list, spans_list = [], []\n",
    "        end_batch = False\n",
    "        for words, spans in self.sent_to_token(raw_text):\n",
    "            end_batch = True\n",
    "            words_list.append(words)\n",
    "            spans_list.append(spans)\n",
    "            if len(spans_list) >= batch_size:\n",
    "                input_ids, attention_mask, token_type_ids, mask = self.tokenize_batch(words_list)\n",
    "                yield (input_ids, attention_mask, token_type_ids, mask), words_list, spans_list\n",
    "                words_list, spans_list = [], []\n",
    "        if end_batch and len(words_list) > 0:\n",
    "            input_ids, attention_mask, token_type_ids, mask = self.tokenize_batch(words_list)\n",
    "            yield (input_ids, attention_mask, token_type_ids, mask), words_list, spans_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJQ8xMLaNUX_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NER\n",
    "NER Interface : We Use this interface to infer sentence Time-Date tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1UKVydicabm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NER(object):\n",
    "\n",
    "    def __init__(self, model_path, model_name = MODEL_NAME, tags = TAGS_TABLE):\n",
    "        \n",
    "        self.tags = tags\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        # Load Pre-Trained model\n",
    "        roberta_path = \"xlm-roberta-base\"\n",
    "        self.model = NERModel(n_labels=len(self.tags), roberta_path=roberta_path).to(self.device)\n",
    "        # Load Fine-Tuned model\n",
    "        state_dict = torch.load(os.path.join(model_path, model_name))\n",
    "        self.model.load_state_dict(state_dict, strict=False)\n",
    "        # Enable Evaluation mode\n",
    "        self.model.eval()\n",
    "        self.tokenizer = NERTokenizer(base_model=roberta_path, to_device=self.device)\n",
    "\n",
    "    # Predict and Pre/Post-Process the input/output\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, raw_text):\n",
    "\n",
    "        outputs_flat, spans_flat, entities = [], [], []\n",
    "        for batch, words, spans in self.tokenizer.prepare_row_text(raw_text):\n",
    "            output, pad_mask = self.model.predict(batch)\n",
    "            outputs_flat.extend(output[pad_mask.bool()].reshape(-1).tolist())\n",
    "            spans_flat += sum(spans, [])\n",
    "\n",
    "        for tag_idx,(start,end) in zip(outputs_flat,spans_flat):\n",
    "            tag = self.tags[tag_idx]\n",
    "            # filter out O tags\n",
    "            if tag != 'O':\n",
    "                entities.append({'Text': raw_text[start:end], \n",
    "                                 'Tag': tag, \n",
    "                                 'Start':start,\n",
    "                                 'End': end})\n",
    "\n",
    "        return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmyhSl6qPPqV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test HengamTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGF0w7aIYHOX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219,
     "referenced_widgets": [
      "bf51448eb2e74e8daa9c30ca39e832c8",
      "507bead0638046288f456ae510c2a5b0",
      "8b84d395875244798710a327910d05a8",
      "68bf0fbf7bf54124a79c455290fbb354",
      "950c39814e554eb2992b60eb4b2aaa56",
      "02717a5022b7431ca4768503f13905f6",
      "b7645eaec1274b4aa905788fadcb024b",
      "b35f53b5510840d9b2c64255c9cc861c",
      "57092c1412c24f91a9ad2b27016fec71",
      "ba9e037daa5d4b90b881841e75fdd6d1",
      "7a3e710e90ad4bad8c084a30368e4704",
      "9756bf94548843e5b3704e0ac7bc766b",
      "3bea868a2ffc491584bf2093e2f4ff97",
      "68a06ccfe4a74794a8fcd25694a3a734",
      "9fd8ee559c29445fbd98d222cb142ced",
      "0f005fff405644e5a5df5426fd3f049c",
      "3b13a0a51e37475787a6ea40a7c96b4d",
      "bc49fe39c54d48b6a4b1d5756c340f6c",
      "5f6bbeff39d04973ab6ce1adc61519e3",
      "f876741d89d24de69cd7bf668cd38ff6",
      "4ea95499a13949b59c16fea5e263fa30",
      "406286bfb7764d2abae6c9fdb22e63da",
      "d518139e60b843959c70ca58c9ffaa01",
      "a5031d9515024ab8a75cd38c4a3cc1fa",
      "694264b960f343e0a8b3a1a5917774e6",
      "fb999509605c4c5d833dbc02c00c7f7e",
      "adc08838d74b47fbbfa3da3e52a91644",
      "954c783bf1c84c28b610efe4d04b9c49",
      "c6abb9ac9c0a4d3cb7a4de7a2d8eba96",
      "dad73578a382498fb29a736be059688d",
      "d7444f49f6734447a13292986fbb3b63",
      "6d6b3c85baf54aeea5bbd5ca12ec62ea",
      "a7b11571075d4abca4966c54bbff18f1",
      "0b81b583f72843659e84fca2a471f953",
      "426856af1469422e8e896fbcdb3ad9b6",
      "8e5b3e39256144f2891abb5df5d11225",
      "7a2a7291dda448b6afab577fce7583f5",
      "07ae54fd86da4a2d865c0d7762e16ac0",
      "4bb8795e893d42219d774e6b8200c276",
      "f5b85862e65f4f01905fcac0341e3394",
      "e96c864ee8964a5d89fd8f27aa951595",
      "9c42a4d6a8b64a9989f1f1aa7a558a14",
      "213ee56be9a04b08a355917de72e8287",
      "17b8ced3953d40b4877512214a4f97ec"
     ]
    },
    "outputId": "9fc53159-20e1-4b7e-fcd8-7d47ecfcc252",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf51448eb2e74e8daa9c30ca39e832c8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9756bf94548843e5b3704e0ac7bc766b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d518139e60b843959c70ca58c9ffaa01"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b81b583f72843659e84fca2a471f953"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Load pretrained model.\n",
    "ner = NER(model_path = '.', model_name = \"HengamTransA.pth\", tags = TAGS_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ner(\"دوشنبه ها صبح به مدرسه می‌رویم.\")"
   ],
   "metadata": {
    "id": "s62VSZiND2pg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8da52a82-710c-4def-9626-baeae10aa3a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'End': 6, 'Start': 0, 'Tag': 'B-DAT', 'Text': 'دوشنبه'},\n",
       " {'End': 9, 'Start': 7, 'Tag': 'I-DAT', 'Text': 'ها'},\n",
       " {'End': 13, 'Start': 10, 'Tag': 'B-TIM', 'Text': 'صبح'}]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "accelerator": "GPU",
  "gpuClass": "standard",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "bf51448eb2e74e8daa9c30ca39e832c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_507bead0638046288f456ae510c2a5b0",
       "IPY_MODEL_8b84d395875244798710a327910d05a8",
       "IPY_MODEL_68bf0fbf7bf54124a79c455290fbb354"
      ],
      "layout": "IPY_MODEL_950c39814e554eb2992b60eb4b2aaa56"
     }
    },
    "507bead0638046288f456ae510c2a5b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02717a5022b7431ca4768503f13905f6",
      "placeholder": "​",
      "style": "IPY_MODEL_b7645eaec1274b4aa905788fadcb024b",
      "value": "Downloading: 100%"
     }
    },
    "8b84d395875244798710a327910d05a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b35f53b5510840d9b2c64255c9cc861c",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57092c1412c24f91a9ad2b27016fec71",
      "value": 615
     }
    },
    "68bf0fbf7bf54124a79c455290fbb354": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba9e037daa5d4b90b881841e75fdd6d1",
      "placeholder": "​",
      "style": "IPY_MODEL_7a3e710e90ad4bad8c084a30368e4704",
      "value": " 615/615 [00:00&lt;00:00, 6.17kB/s]"
     }
    },
    "950c39814e554eb2992b60eb4b2aaa56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02717a5022b7431ca4768503f13905f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7645eaec1274b4aa905788fadcb024b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b35f53b5510840d9b2c64255c9cc861c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57092c1412c24f91a9ad2b27016fec71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ba9e037daa5d4b90b881841e75fdd6d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a3e710e90ad4bad8c084a30368e4704": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9756bf94548843e5b3704e0ac7bc766b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bea868a2ffc491584bf2093e2f4ff97",
       "IPY_MODEL_68a06ccfe4a74794a8fcd25694a3a734",
       "IPY_MODEL_9fd8ee559c29445fbd98d222cb142ced"
      ],
      "layout": "IPY_MODEL_0f005fff405644e5a5df5426fd3f049c"
     }
    },
    "3bea868a2ffc491584bf2093e2f4ff97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b13a0a51e37475787a6ea40a7c96b4d",
      "placeholder": "​",
      "style": "IPY_MODEL_bc49fe39c54d48b6a4b1d5756c340f6c",
      "value": "Downloading: 100%"
     }
    },
    "68a06ccfe4a74794a8fcd25694a3a734": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f6bbeff39d04973ab6ce1adc61519e3",
      "max": 1115590446,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f876741d89d24de69cd7bf668cd38ff6",
      "value": 1115590446
     }
    },
    "9fd8ee559c29445fbd98d222cb142ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ea95499a13949b59c16fea5e263fa30",
      "placeholder": "​",
      "style": "IPY_MODEL_406286bfb7764d2abae6c9fdb22e63da",
      "value": " 1.04G/1.04G [00:22&lt;00:00, 56.9MB/s]"
     }
    },
    "0f005fff405644e5a5df5426fd3f049c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b13a0a51e37475787a6ea40a7c96b4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc49fe39c54d48b6a4b1d5756c340f6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f6bbeff39d04973ab6ce1adc61519e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f876741d89d24de69cd7bf668cd38ff6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ea95499a13949b59c16fea5e263fa30": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "406286bfb7764d2abae6c9fdb22e63da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d518139e60b843959c70ca58c9ffaa01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5031d9515024ab8a75cd38c4a3cc1fa",
       "IPY_MODEL_694264b960f343e0a8b3a1a5917774e6",
       "IPY_MODEL_fb999509605c4c5d833dbc02c00c7f7e"
      ],
      "layout": "IPY_MODEL_adc08838d74b47fbbfa3da3e52a91644"
     }
    },
    "a5031d9515024ab8a75cd38c4a3cc1fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_954c783bf1c84c28b610efe4d04b9c49",
      "placeholder": "​",
      "style": "IPY_MODEL_c6abb9ac9c0a4d3cb7a4de7a2d8eba96",
      "value": "Downloading: 100%"
     }
    },
    "694264b960f343e0a8b3a1a5917774e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dad73578a382498fb29a736be059688d",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7444f49f6734447a13292986fbb3b63",
      "value": 5069051
     }
    },
    "fb999509605c4c5d833dbc02c00c7f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d6b3c85baf54aeea5bbd5ca12ec62ea",
      "placeholder": "​",
      "style": "IPY_MODEL_a7b11571075d4abca4966c54bbff18f1",
      "value": " 4.83M/4.83M [00:00&lt;00:00, 16.9MB/s]"
     }
    },
    "adc08838d74b47fbbfa3da3e52a91644": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "954c783bf1c84c28b610efe4d04b9c49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6abb9ac9c0a4d3cb7a4de7a2d8eba96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dad73578a382498fb29a736be059688d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7444f49f6734447a13292986fbb3b63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d6b3c85baf54aeea5bbd5ca12ec62ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7b11571075d4abca4966c54bbff18f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b81b583f72843659e84fca2a471f953": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_426856af1469422e8e896fbcdb3ad9b6",
       "IPY_MODEL_8e5b3e39256144f2891abb5df5d11225",
       "IPY_MODEL_7a2a7291dda448b6afab577fce7583f5"
      ],
      "layout": "IPY_MODEL_07ae54fd86da4a2d865c0d7762e16ac0"
     }
    },
    "426856af1469422e8e896fbcdb3ad9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bb8795e893d42219d774e6b8200c276",
      "placeholder": "​",
      "style": "IPY_MODEL_f5b85862e65f4f01905fcac0341e3394",
      "value": "Downloading: 100%"
     }
    },
    "8e5b3e39256144f2891abb5df5d11225": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e96c864ee8964a5d89fd8f27aa951595",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c42a4d6a8b64a9989f1f1aa7a558a14",
      "value": 9096718
     }
    },
    "7a2a7291dda448b6afab577fce7583f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_213ee56be9a04b08a355917de72e8287",
      "placeholder": "​",
      "style": "IPY_MODEL_17b8ced3953d40b4877512214a4f97ec",
      "value": " 8.68M/8.68M [00:00&lt;00:00, 33.3MB/s]"
     }
    },
    "07ae54fd86da4a2d865c0d7762e16ac0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bb8795e893d42219d774e6b8200c276": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5b85862e65f4f01905fcac0341e3394": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e96c864ee8964a5d89fd8f27aa951595": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c42a4d6a8b64a9989f1f1aa7a558a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "213ee56be9a04b08a355917de72e8287": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b8ced3953d40b4877512214a4f97ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}